{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "yColumn = \"Survived\"\n",
    "dfTrain = pd.read_csv(\"./train.csv\")\n",
    "dfTest = pd.read_csv(\"./test.csv\")\n",
    "\n",
    "y = dfTrain[yColumn]\n",
    "dfTrain.drop(yColumn, axis=1, inplace=True)\n",
    "X_full = dfTrain.append(dfTest, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjustDataframe(dataFrame):\n",
    "##  Get name prefix\n",
    "    namePrefix = dataFrame[\"Name\"].str.split(', ', 1).str[1]\n",
    "    namePrefix = namePrefix.str.split('. ',1).str[0]\n",
    "    dataFrame[\"NamePrefix\"] = namePrefix\n",
    "##  Split ticket into numeric and prefix parts\n",
    "    spacedTicket = ' ' + dataFrame['Ticket'].astype(str)\n",
    "    ticketSplit = spacedTicket.str.rsplit(' ',1,expand=True)\n",
    "    dataFrame[\"TicketPrefix\"] = ticketSplit[0]\n",
    "    dataFrame[\"TicketPrefix\"] = dataFrame[\"TicketPrefix\"].str.replace(\".\",\"\")\n",
    "    dataFrame[\"TicketPrefix\"] = dataFrame[\"TicketPrefix\"].str.replace(\" \",\"\")\n",
    "    dataFrame[\"TicketNumber\"] = ticketSplit[1]  \n",
    "#Check if there were NaN for those columns\n",
    "    dataFrame[\"FamilySize\"] = dataFrame[\"SibSp\"] + dataFrame[\"Parch\"]  + 1\n",
    "\n",
    "## There are multiple cabins per some of passengers - how to proceed?\n",
    "# For now I will only use deck name and amount of cabins. For later I should check how could I use multiple entries\n",
    "    dataFrame[\"CabinDeck\"] = dataFrame[\"Cabin\"].str[:1]\n",
    "    dataFrame[\"CabinsAmount\"] = dataFrame[\"Cabin\"].str.split(\" \",-1).str.len()\n",
    "\n",
    "    del namePrefix, spacedTicket, ticketSplit\n",
    "    dataFrame.drop([\"Name\", \"Ticket\", \"Cabin\"], axis=1, inplace=True)\n",
    "    return dataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fare and Pclass have highest correlations. Low correlations: Age, Parch.  SibSp and PassengerId correlation < 0.05\n",
    "#XTrain.corrwith(y)\n",
    "X_full = adjustDataframe(X_full)\n",
    "X_full = X_full.replace(r'^\\s*$', np.nan, regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove Nan values in all relevant columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove nan values and transform categories into separate column for each column value\n",
    "numericColumns = [\"Pclass\", \"Age\", \"FamilySize\", \"Fare\", \"CabinsAmount\"]\n",
    "categoricalColumns = [\"Sex\",\"NamePrefix\", \"TicketPrefix\", \"CabinDeck\", \"Embarked\"]\n",
    "\n",
    "mean_Imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "X_numeric = mean_Imputer.fit_transform(X_full[numericColumns])\n",
    "X_numeric = StandardScaler().fit_transform(X_numeric)\n",
    "categorical_data = X_full[categoricalColumns].fillna(\"N/A\").astype(str)\n",
    "encoder = DictVectorizer(sparse = False)\n",
    "X_categorical = encoder.fit_transform(categorical_data.T.to_dict().values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data back to train and test\n",
    "X_train = np.hstack((X_numeric[0:891,:],X_categorical[0:891,:]))\n",
    "X_final_test = np.hstack((X_numeric[891:1309,:],X_categorical[891:1309,:]))\n",
    "# Test set from Kaggle does not have prediction result, so I should split training set\n",
    "X_tmp_train, X_tmp_test, y_tmp_train, y_tmp_test = train_test_split(X_train, y)\n",
    "\n",
    "# np.corrcoef(X_train[:,1], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "CV  2 Lambda  9 Train score  0.7889221556886228 Test score  0.8609865470852018\nCV  3 Lambda  1 Train score  0.8008982035928144 Test score  0.8430493273542601\nCV  4 Lambda  0.1 Train score  0.7889221556886228 Test score  0.8026905829596412\nCV  5 Lambda  1 Train score  0.8008982035928144 Test score  0.8430493273542601\nCV  6 Lambda  1 Train score  0.8008982035928144 Test score  0.8430493273542601\nCV  7 Lambda  1 Train score  0.8008982035928144 Test score  0.8430493273542601\n"
    }
   ],
   "source": [
    "#param_grid = {'C': [0.01, 0.05, 0.1, 0.5, 1, 5, 10]}\n",
    "param_grid={ 'C': [0.01, 0.05, 0.1, 0.5, 1, 5, 7, 8, 9, 10]}\n",
    "cvList = [2,3,4,5,6,7]\n",
    "for cv in cvList:\n",
    "    \n",
    "    #cv = 4\n",
    "    optimizer = GridSearchCV(LogisticRegression(class_weight='balanced', fit_intercept=True, penalty=\"l2\"), param_grid, cv=cv, n_jobs=-1)\n",
    "    #optimizer = GridSearchCV(LogisticRegression(class_weight='balanced', fit_intercept=True, penalty=\"l2\"), param_grid, cv = cv, n_jobs=-1)\n",
    "    # Probably put full training data set here?\n",
    "    optimizer.fit(X_tmp_train, y_tmp_train)\n",
    "    # print(optimizer.best_estimator_)\n",
    "    # print(\"Score \",optimizer.best_score_)\n",
    "    optimizer.fit(X_tmp_test, y_tmp_test)\n",
    "    # optimizer.best_score_\n",
    "    scoreTrain = optimizer.score(X_tmp_train, y_tmp_train)\n",
    "    scoreTest = optimizer.score(X_tmp_test, y_tmp_test)\n",
    "    print(\"CV \", cv, \"Lambda \", optimizer.best_estimator_.C, \"Train score \", scoreTrain, \"Test score \", scoreTest)\n",
    "    roc_auc_score(y_tmp_test, optimizer.predict(X_tmp_test))\n",
    "    # first submission score was 0.757, however final result was 0.77\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tests to do:\n",
    "- test if polynomial features could improve the performance\n",
    "- combine sibsp and parch into FamilySize column (sibsp+parch+traveller)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write answer\n",
    "answer = pd.DataFrame(columns=[\"PassengerId\", \"Survived\"])\n",
    "answer[\"PassengerId\"] = dfTest[\"PassengerId\"]\n",
    "answer[\"Survived\"] = optimizer.predict(X_final_test)\n",
    "answer.to_csv(\"answer.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38132bit0e351f7e16f44201b52fbf0158229096",
   "display_name": "Python 3.8.1 32-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}